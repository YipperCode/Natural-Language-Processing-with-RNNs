{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">\n",
        "  <b>Universidad Autónoma de Chihuahua</b>\n",
        "</h1>\n",
        "<h2 align=\"center\">\n",
        "  <b>Facultad de Ingeniaría</b>\n",
        "</h2>\n",
        "<br>\n",
        "<p align = \"center\">\n",
        "  <a href=\"https://sega.uach.mx/\">\n",
        "     <img src=\"https://drive.google.com/uc?id=1n8NdPSF4WAZRxVomm74jf0zLU9ibdxqT\">\n",
        "  </a>\n",
        "</p>\n",
        "\n",
        "<h1 align=\"center\">\n",
        "  <b>Natural Language Processing with RNNs</b>\n",
        "</h1>\n",
        "<br>\n",
        "\n",
        "<h2 align=\"center\">\n",
        "  <b>Data Science</b>\n",
        "</h2>\n",
        "\n",
        "<h3 align=\"center\">\n",
        "  <b>Proyecto Tercer Parcial</b>\n",
        "</h3>\n",
        "<br>\n",
        "<p align=\"center\">\n",
        "<b>Link GitHub</b><br>\n",
        "<href> </href>\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "  <b>Alumnos: </b><br>\n",
        "  Juan Luis Del Valle Sotelo - 338912 \n",
        "  <br>\n",
        "  Valeria Sofía Nevárez Juárez - 338811\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "  <b>Profesor:</b>\n",
        "  Jesús Roberto López Santillán\n",
        "</p>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "<p align=\"left\">\n",
        "  A miércoles 24 de mayo de 2023\n",
        "</p>"
      ],
      "metadata": {
        "id": "Ukd9y108swfy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nFxCC9xr6kB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "if IS_COLAB:\n",
        "    %pip install -q -U tensorflow-addons\n",
        "    %pip install -q -U transformers\n",
        "\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "    if IS_KAGGLE:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"nlp\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr0tbTAnr6kD",
        "scrolled": true,
        "outputId": "12fb90d8-70cf-404b-cb68-b1b57676e25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "____________________ Batch 0 \n",
            "X_batch\n",
            "[[6 7 8 9]\n",
            " [2 3 4 5]\n",
            " [4 5 6 7]]\n",
            "===== \n",
            "Y_batch\n",
            "[[ 7  8  9 10]\n",
            " [ 3  4  5  6]\n",
            " [ 5  6  7  8]]\n",
            "____________________ Batch 1 \n",
            "X_batch\n",
            "[[ 0  1  2  3]\n",
            " [ 8  9 10 11]\n",
            " [10 11 12 13]]\n",
            "===== \n",
            "Y_batch\n",
            "[[ 1  2  3  4]\n",
            " [ 9 10 11 12]\n",
            " [11 12 13 14]]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "n_steps = 5\n",
        "dataset = tf.data.Dataset.from_tensor_slices(tf.range(15))\n",
        "dataset = dataset.window(n_steps, shift=2, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(n_steps))\n",
        "dataset = dataset.shuffle(10).map(lambda window: (window[:-1], window[1:]))\n",
        "dataset = dataset.batch(3).prefetch(1)\n",
        "for index, (X_batch, Y_batch) in enumerate(dataset):\n",
        "    print(\"_\" * 20, \"Batch\", index, \"\\nX_batch\")\n",
        "    print(X_batch.numpy())\n",
        "    print(\"=\" * 5, \"\\nY_batch\")\n",
        "    print(Y_batch.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVKuY_LIr6kE"
      },
      "source": [
        "## Loading the Data and Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcxNfM_sB8l7"
      },
      "outputs": [],
      "source": [
        "file_path = \"south_park.txt\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TvL_m4Zr6kE"
      },
      "outputs": [],
      "source": [
        "with open(file_path, 'r') as file:\n",
        "    file_contents = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcGhrd_PG69y"
      },
      "outputs": [],
      "source": [
        "unwanted_chars = \"àáâäèéëíîñóôöúüабйнтщў؟آابتثخدرزشعفلمنهوچکی™\"\n",
        "\n",
        "translation_table = str.maketrans(\"\", \"\", unwanted_chars)\n",
        "south_park_text = file_contents.translate(translation_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaEfiPrHr6kE",
        "outputId": "f26a04b2-a21d-4321-a87d-4276475f271d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stan \n",
            "You guys, you guys! Chef is going away. \n",
            "\n",
            "Kyle\n",
            "Going away? For how long?\n",
            "\n",
            "Stan\n",
            "Forever.\n",
            "\n",
            "Chef\n",
            "I'm sorry boys.\n",
            "\n",
            "Stan\n",
            "Chef said he's been bored, so he joining a group called the Super Adventure Cl\n"
          ]
        }
      ],
      "source": [
        "print(south_park_text[:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qRNw-73xr6kF",
        "outputId": "f3e5a8a0-36e5-475f-ed0c-f1b9da19697c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\t\\n !#$%&'()*+,-./0123456789:;=?@_abcdefghijklmnopqrstuvwxyz¡¿’\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "\"\".join(sorted(set(south_park_text.lower())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhNbmGGur6kF"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(south_park_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDKvCNw2r6kF",
        "outputId": "df9e9fa4-37f1-4d9e-e013-a7612a8eec39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[25, 7, 9, 8, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([\"First\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXFg43CHr6kF",
        "outputId": "c62d7e69-2cf2-4709-a80f-a761337a3e61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "tokenizer.sequences_to_texts([[25, 7, 9, 8, 3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnU_UHjTr6kG"
      },
      "outputs": [],
      "source": [
        "max_id = len(tokenizer.word_index) \n",
        "dataset_size = tokenizer.document_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRv6lkjfr6kG"
      },
      "outputs": [],
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([south_park_text])) - 1\n",
        "train_size = dataset_size * 90 // 100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "010I8n43r6kG"
      },
      "outputs": [],
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1 \n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sze3bf7pr6kG"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2ozj-fAr6kG"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEEX4agwr6kG"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHdrvubdr6kH"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X8SNDsbr6kH"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC8-Rosrr6kH",
        "outputId": "4167527d-297f-410a-d994-16baa84e3212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100, 62) (32, 100)\n"
          ]
        }
      ],
      "source": [
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf_d91wCr6kH"
      },
      "source": [
        "## Creating and Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnDoZj-yr6kH",
        "outputId": "15c7e809-e4f7-42f9-c8e7-71b23493e28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "38327/38327 [==============================] - 606s 16ms/step - loss: 1.5378\n",
            "Epoch 2/15\n",
            "38327/38327 [==============================] - 525s 14ms/step - loss: 1.4552\n",
            "Epoch 3/15\n",
            "38327/38327 [==============================] - 540s 14ms/step - loss: 1.4349\n",
            "Epoch 4/15\n",
            "38327/38327 [==============================] - 541s 14ms/step - loss: 1.4246\n",
            "Epoch 5/15\n",
            "38327/38327 [==============================] - 533s 14ms/step - loss: 1.4184\n",
            "Epoch 6/15\n",
            "38327/38327 [==============================] - 535s 14ms/step - loss: 1.4137\n",
            "Epoch 7/15\n",
            "38327/38327 [==============================] - 528s 14ms/step - loss: 1.4103\n",
            "Epoch 8/15\n",
            "38327/38327 [==============================] - 552s 14ms/step - loss: 1.4072\n",
            "Epoch 9/15\n",
            "38327/38327 [==============================] - 534s 14ms/step - loss: 1.4046\n",
            "Epoch 10/15\n",
            "38327/38327 [==============================] - 526s 14ms/step - loss: 1.4027\n",
            "Epoch 11/15\n",
            "38327/38327 [==============================] - 526s 14ms/step - loss: 1.4010\n",
            "Epoch 12/15\n",
            "38327/38327 [==============================] - 537s 14ms/step - loss: 1.3998\n",
            "Epoch 13/15\n",
            "38327/38327 [==============================] - 527s 14ms/step - loss: 1.3985\n",
            "Epoch 14/15\n",
            "38327/38327 [==============================] - 537s 14ms/step - loss: 1.3975\n",
            "Epoch 15/15\n",
            "38327/38327 [==============================] - 527s 14ms/step - loss: 1.3962\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
        "                     dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True,\n",
        "                     dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, epochs=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRJEtAa5r6kH"
      },
      "source": [
        "## Using the Model to Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj14efyCr6kH"
      },
      "outputs": [],
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYo4tX95r6kI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bea48f03-c792-4eb2-e6b8-42d59a7fcb94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "X_new = preprocess([\"How are yo\"])\n",
        "Y_pred = np.argmax(model(X_new), axis=-1)\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mumpLKb9r6kI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b54a9b9-2d1d-4958-d584-51d85c10916d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "        2, 0, 0, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mKDU9aLr6kI"
      },
      "outputs": [],
      "source": [
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK3rPN8xr6kI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a292d03e-6fc3-4a5f-e35d-c5baef19f414"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "next_char(\"How are yo\", temperature=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vRWuWmCr6kI"
      },
      "outputs": [],
      "source": [
        "def complete_text(text, n_chars=1000, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt52782wr6kT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f189b4-7419-4487-edc1-b9f1b02fc942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t i should help and together help!  kick you mysterion. branding them about what i think that you gotuen anymore, complete you guys?  tupperwar, and soon, is dead weth unshou sesurer tacklite because etoses sack.  or, in a stopping crilnd of the coon. i actually it feel lekens! the wrong is, he're actually even destroy factices! but the coon and friends how cthulhu is just started people is wrong?!\n",
            "\n",
            "coon\n",
            "look, what should i do? \n",
            "\n",
            "singer\n",
            "right, fucking guy!\n",
            "\n",
            "toolshed\n",
            "aww! where happened?! \n",
            "\n",
            "mosquito\n",
            "yeah, no. \n",
            "\n",
            "liane\n",
            "yes, because it's my undically grautan' shop even and coon, 'cause i'll totally be done into another dimension. and an the gleas rainbow.\n",
            "\n",
            "coon\n",
            "what do you mean as this curse? be should we do?\n",
            "\n",
            "memt reporter\n",
            "coon one reamonion. without him.\n",
            "\n",
            "toolshed\n",
            "all when we're gonna die-\n",
            "\n",
            "woman k\n",
            "toolshed!\n",
            "\n",
            "toolshed\n",
            "gotard! dude. you soon, mysterion! let's go home! \n",
            "\n",
            "red goth\n",
            "i'll took dembsibey, per-that evil called owe my name!\n",
            "\n",
            "loane\n",
            "so the dark lord age!\n",
            "\n",
            "coon\n",
            "no! baby ap\n",
            "lot right,\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "print(complete_text(\"t\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZskcQ4ar6kU"
      },
      "source": [
        "## Stateful RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vPX_Zwor6kU"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHNYUgGcr6kU"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "dataset = dataset.batch(1)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr1z_Jt4r6kU"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
        "datasets = []\n",
        "for encoded_part in encoded_parts:\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
        "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "    datasets.append(dataset)\n",
        "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFx1fOaRr6kU"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     dropout=0.2,\n",
        "                     batch_input_shape=[batch_size, None, max_id]),\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yZOWWV-r6kU"
      },
      "outputs": [],
      "source": [
        "class ResetStatesCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpEGnR6tr6kU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62bd22a-4c46-4284-a216-81916731a6b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "383/383 [==============================] - 11s 21ms/step - loss: 2.6746\n",
            "Epoch 2/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 2.2306\n",
            "Epoch 3/50\n",
            "383/383 [==============================] - 6s 16ms/step - loss: 2.0814\n",
            "Epoch 4/50\n",
            "383/383 [==============================] - 8s 20ms/step - loss: 2.0028\n",
            "Epoch 5/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.9514\n",
            "Epoch 6/50\n",
            "383/383 [==============================] - 8s 20ms/step - loss: 1.9133\n",
            "Epoch 7/50\n",
            "383/383 [==============================] - 6s 17ms/step - loss: 1.8860\n",
            "Epoch 8/50\n",
            "383/383 [==============================] - 7s 19ms/step - loss: 1.8636\n",
            "Epoch 9/50\n",
            "383/383 [==============================] - 6s 17ms/step - loss: 1.8470\n",
            "Epoch 10/50\n",
            "383/383 [==============================] - 6s 16ms/step - loss: 1.8314\n",
            "Epoch 11/50\n",
            "383/383 [==============================] - 8s 20ms/step - loss: 1.8184\n",
            "Epoch 12/50\n",
            "383/383 [==============================] - 7s 18ms/step - loss: 1.8071\n",
            "Epoch 13/50\n",
            "383/383 [==============================] - 7s 18ms/step - loss: 1.7992\n",
            "Epoch 14/50\n",
            "383/383 [==============================] - 6s 16ms/step - loss: 1.7893\n",
            "Epoch 15/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.7805\n",
            "Epoch 16/50\n",
            "383/383 [==============================] - 6s 16ms/step - loss: 1.7747\n",
            "Epoch 17/50\n",
            "383/383 [==============================] - 8s 21ms/step - loss: 1.7662\n",
            "Epoch 18/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.7599\n",
            "Epoch 19/50\n",
            "383/383 [==============================] - 7s 19ms/step - loss: 1.7555\n",
            "Epoch 20/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.7529\n",
            "Epoch 21/50\n",
            "383/383 [==============================] - 7s 19ms/step - loss: 1.7462\n",
            "Epoch 22/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.7403\n",
            "Epoch 23/50\n",
            "383/383 [==============================] - 6s 16ms/step - loss: 1.7371\n",
            "Epoch 24/50\n",
            "383/383 [==============================] - 8s 21ms/step - loss: 1.7331\n",
            "Epoch 25/50\n",
            "383/383 [==============================] - 6s 16ms/step - loss: 1.7295\n",
            "Epoch 26/50\n",
            "383/383 [==============================] - 8s 20ms/step - loss: 1.7263\n",
            "Epoch 27/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.7237\n",
            "Epoch 28/50\n",
            "383/383 [==============================] - 7s 17ms/step - loss: 1.7197\n",
            "Epoch 29/50\n",
            "383/383 [==============================] - 8s 21ms/step - loss: 1.7170\n",
            "Epoch 30/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.7153\n",
            "Epoch 31/50\n",
            "383/383 [==============================] - 8s 20ms/step - loss: 1.7122\n",
            "Epoch 32/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.7087\n",
            "Epoch 33/50\n",
            "383/383 [==============================] - 9s 24ms/step - loss: 1.7071\n",
            "Epoch 34/50\n",
            "383/383 [==============================] - 8s 20ms/step - loss: 1.7057\n",
            "Epoch 35/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.7035\n",
            "Epoch 36/50\n",
            "383/383 [==============================] - 8s 20ms/step - loss: 1.6996\n",
            "Epoch 37/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.6988\n",
            "Epoch 38/50\n",
            "383/383 [==============================] - 8s 20ms/step - loss: 1.6955\n",
            "Epoch 39/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.6948\n",
            "Epoch 40/50\n",
            "383/383 [==============================] - 8s 21ms/step - loss: 1.6927\n",
            "Epoch 41/50\n",
            "383/383 [==============================] - 6s 17ms/step - loss: 1.6924\n",
            "Epoch 42/50\n",
            "383/383 [==============================] - 7s 19ms/step - loss: 1.6895\n",
            "Epoch 43/50\n",
            "383/383 [==============================] - 8s 20ms/step - loss: 1.6868\n",
            "Epoch 44/50\n",
            "383/383 [==============================] - 6s 16ms/step - loss: 1.6876\n",
            "Epoch 45/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.6821\n",
            "Epoch 46/50\n",
            "383/383 [==============================] - 7s 18ms/step - loss: 1.6847\n",
            "Epoch 47/50\n",
            "383/383 [==============================] - 7s 18ms/step - loss: 1.6818\n",
            "Epoch 48/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.6808\n",
            "Epoch 49/50\n",
            "383/383 [==============================] - 8s 21ms/step - loss: 1.6807\n",
            "Epoch 50/50\n",
            "383/383 [==============================] - 6s 15ms/step - loss: 1.6804\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, epochs=50,\n",
        "                    callbacks=[ResetStatesCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbZT0Oypr6kV"
      },
      "outputs": [],
      "source": [
        "stateless_model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWQAwQErr6kV"
      },
      "outputs": [],
      "source": [
        "stateless_model.build(tf.TensorShape([None, None, max_id]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUlP-MVFr6kV"
      },
      "outputs": [],
      "source": [
        "stateless_model.set_weights(model.get_weights())\n",
        "model = stateless_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c03yaCdFr6kV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6d7846-11ca-4b89-8381-3b8f46418e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cartman\n",
            "the fuck here are to the walk, then you thanks to fig brand?\n",
            "\n",
            "mr. mackey\n",
            "get arout warchist you, buke, but, i'm just going to be of the night, and you grist soes to the las somebody aren't real?\n",
            "\n",
            "cartman\n",
            "isn't a little new of said's knowed to keep shut the dad, i'm gonna did it to really addew here, we had to deptine and inshur. i've way-\n",
            "\n",
            "stan\n",
            "what is that?!\n",
            "\n",
            "butters\n",
            "just to a speak is bexise your hark. i'm not sorry, they peet the thried is the country, and i moaas.\n",
            "\n",
            "welly\n",
            "how chen?! \n",
            "\n",
            "boy\n",
            "mush, i'm gonna foll brywhide cartumate d-!\n",
            "\n",
            "croid and now, we shopped that put of 'he jimmy's popvy party guy in showidnel big... \n",
            "\n",
            "louse 2\n",
            "it's going on, really gonna kyle video the fact is cure. it's trying.\n",
            "\n",
            "cartman\n",
            "i have to think of the hoado?\n",
            "\n",
            "liane\n",
            "oh, let's in.\n",
            "\n",
            "kyle\n",
            "hww you don't keep me where!  you're doing!\n",
            "\n",
            "butters\n",
            "hello, don't you sool kyle! i'm neliing that?\n",
            "\n",
            "cartman\n",
            "dube it wouldn't you dead. eyee are writtle guy. i stand some of the makes and now lage!\n",
            "\n",
            "cartman\n",
            "mimsy, p\n",
            "lat 2\n",
            "sort\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "print(complete_text(\"cartman\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusión\n",
        "\n"
      ],
      "metadata": {
        "id": "TkVD-YAIzDQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "En resumen, las redes neuronales recurrentes (RNN) pueden mostrar y completar palabras, pero carecen de sentido gramatical. En este caso, se habría podido mejorar el rendimiento corriendo el modelo durante más épocas, pero se enfrentaron problemas de desconexión en Google Colab. A pesar de sus limitaciones, las RNN pueden ser útiles en contextos creativos o como punto de partida para generar texto más avanzado. Mejorar y refinar estos modelos en el futuro puede llevar a resultados más coherentes y comprensibles."
      ],
      "metadata": {
        "id": "tpdfntaizJZ0"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}